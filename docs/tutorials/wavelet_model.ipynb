{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starlet Tutorial\n",
    "\n",
    "This tutorial goes through a case where the default `ExtendedSource` models will struggle: a complex low surface brightness galaxy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word on starlets\n",
    "\n",
    "Starlets are a familly of functions that are generative of the ensemble of real matrices of finite sahpes and overcomplete. In that regard, shapelets have the flexibility to represent any pixelated 2-D profile. We take advantage of this property and use starlets to model sources with features that are too complex to be modeled with only assumptions of symmetry or monotonicity, such as irregular galaxies and spiral galaxies.\n",
    "\n",
    "But first, the usual incantation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import astropy.io.fits as fits\n",
    "import sep \n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a superior colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='gist_stern', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Data\n",
    "\n",
    "We load the data set (an image cube with 5 bands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "data = pickle.load(open(\"../../data/lsbg.pkl\", \"rb\"))\n",
    "images = data[\"images\"]\n",
    "filters = data[\"channels\"]\n",
    "psf = data[\"psfs\"]\n",
    "\n",
    "from scarlet.display import AsinhMapping\n",
    "\n",
    "stretch = 1\n",
    "Q = 5\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection Catalog\n",
    "\n",
    "Because we don't have a detection catalog, we need to build one. We'll use a combination of wavelet filtering and [SEP](http://sep.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCatalog(datas, lvl=3, wave=True):\n",
    "    ''' Creates a detection catalog by combining low and high resolution data\n",
    "    Parameters\n",
    "    ----------\n",
    "    datas: array\n",
    "        array of Data objects\n",
    "    lvl: int\n",
    "        detection lvl\n",
    "    wave: Bool\n",
    "        set to True to use wavelet decomposition of images before combination\n",
    "    Returns\n",
    "    -------\n",
    "    catalog: sextractor catalog\n",
    "        catalog of detected sources\n",
    "    bg_rms: array\n",
    "        background level for each data set\n",
    "    '''\n",
    "    if type(datas) is np.ndarray:\n",
    "        hr_images = datas / np.sum(datas, axis=(1, 2))[:, None, None]\n",
    "        # Detection image as the sum over all images\n",
    "        detect_image = np.sum(hr_images, axis=0)\n",
    "    else:\n",
    "        data_lr, data_hr = datas\n",
    "        # Create observations for each image\n",
    "        # Interpolate low resolution to high resolution\n",
    "        interp = interpolate(data_lr, data_hr)\n",
    "        # Normalisation of the interpolate low res images\n",
    "        interp = interp / np.sum(interp, axis=(1, 2))[:, None, None]\n",
    "        # Normalisation of the high res data\n",
    "        hr_images = data_hr.images / np.sum(data_hr.images, axis=(1, 2))[:, None, None]\n",
    "        # Detection image as the sum over all images\n",
    "        detect_image = np.sum(interp, axis=0) + np.sum(hr_images, axis=0)\n",
    "        detect_image *= np.sum(data_hr.images)\n",
    "    if np.size(detect_image.shape) == 3:\n",
    "        if wave:\n",
    "            # Wavelet detection in the first three levels\n",
    "            wave_detect = Starlet(detect_image.mean(axis=0), lvl=4).coefficients\n",
    "            wave_detect[:, -1, :, :] = 0\n",
    "            detect = scarlet.Starlet(coefficients=wave_detect).image\n",
    "        else:\n",
    "            # Direct detection\n",
    "            detect = detect_image.mean(axis=0)\n",
    "    else:\n",
    "        if wave:\n",
    "            wave_detect = scarlet.Starlet(detect_image).coefficients\n",
    "            detect = wave_detect[0][0] + wave_detect[0][1] + wave_detect[0][2]\n",
    "        else:\n",
    "            detect = detect_image\n",
    "\n",
    "    bkg = sep.Background(detect)\n",
    "    catalog = sep.extract(detect, lvl, err=bkg.globalrms)\n",
    "\n",
    "    if type(datas) is np.ndarray:\n",
    "        bg_rms = scarlet.wavelet.mad_wavelet(datas)\n",
    "    else:\n",
    "        bg_rms = []\n",
    "        for data in datas:\n",
    "            bg_rms.append(scarlet.wavelet.mad_wavelet(data.images))\n",
    "\n",
    "    return catalog, bg_rms\n",
    "\n",
    "#Detection and background noise estimate\n",
    "catalog, bg_rms_hsc = makeCatalog(images, 3, 1)\n",
    "weights = np.ones_like(images) / (bg_rms_hsc**2)[:, None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows how the wavelet transform and inverse transform works in scarlet. As a check we make sure that the transform and its inverse lead to the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare a starlet object (and performs the transform)\n",
    "Sw = scarlet.Starlet(images, lvl = 4, direct = True)\n",
    "#This is the starlet transform as an array\n",
    "w = Sw.coefficients\n",
    "#The inverse starlet transform of w (new object otherwise, the tranform is not used)\n",
    "iw = Sw.image\n",
    "\n",
    "#The wavelet transform of the first slice of images in pictures:\n",
    "lvl = w.shape[1]\n",
    "plt.figure(figsize = (lvl*5+5,5))\n",
    "plt.suptitle('Wavelet coefficients')\n",
    "for i in range(lvl):\n",
    "    plt.subplot(1,lvl,i+1)\n",
    "    plt.title('scale'+str(i+1))\n",
    "    plt.imshow(w[0,i])\n",
    "    plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Making sure we recover the original image:\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.subplot(131)\n",
    "plt.title('Original image', fontsize = 20)\n",
    "plt.imshow(images[0])\n",
    "plt.colorbar()\n",
    "plt.subplot(132)\n",
    "plt.title('Starlet-reconstructed image', fontsize = 20)\n",
    "plt.imshow(iw[0])\n",
    "plt.colorbar()\n",
    "plt.subplot(133)\n",
    "plt.title('Absolute difference', fontsize = 20)\n",
    "plt.imshow((np.abs(iw[0]-images[0])))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if our detection catalog makes sense, let's have a look what has been detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarlet.display import AsinhMapping\n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "# Mark all of the sources from the detection cataog\n",
    "for k, src in enumerate(catalog):\n",
    "    plt.text(src[\"x\"], src[\"y\"], str(k), color=\"red\", fontsize = 25)\n",
    "    plt.plot(src[\"x\"], src[\"y\"], 'rx', markersize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the detected sources, it seems that sources 1 and 4 are individual components, while the central galaxy has a \"red\" component centered around 2 and a blue component particularly bright around 3 and 0. We will use this information to inform the choice of source types we use to model the scene.\n",
    "\n",
    "Here this procedure is done manually, but in the future, we expect that matching images with different colours and complex morphologies might help automating this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Frame and Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can fully specify the `Frame` and `Observation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_psf = scarlet.GaussianPSF(sigma = 0.8)\n",
    "\n",
    "model_frame = scarlet.Frame(\n",
    "    images.shape,\n",
    "    psf=model_psf,\n",
    "    channels=filters)\n",
    "\n",
    "observation = scarlet.Observation(\n",
    "    images, \n",
    "    psf=scarlet.ImagePSF(psf), \n",
    "    weights=weights, \n",
    "    channels=filters).match(model_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Starlet Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize sources\n",
    "\n",
    "We now need to define sources that are going to be fit. The full model, which we will call `Blend`, is a collection of those sources. As mentioned previously, we chose to represent most components as `ExtendedSources`. The tidal features in the image and the extended features are modeled by 3 `StarletSources`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starlet_sources = []\n",
    "for k,src in enumerate(catalog):\n",
    "    if k in [12,13,16]:\n",
    "        new_source = scarlet.StarletSource(model_frame, \n",
    "                        (src[\"x\"], src[\"y\"]), observation, \n",
    "                        starlet_thresh = 1)\n",
    "        starlet_sources.append(new_source)\n",
    "    else:\n",
    "        new_source = scarlet.ExtendedSource(model_frame, \n",
    "                                        (src['y'], src['x']), \n",
    "                                        observation, \n",
    "                                        K=1,\n",
    "                                        compact = 1)\n",
    "        starlet_sources.append(new_source)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Fit Model\n",
    "The `Blend` class represents the sources as a tree and has the machinery to fit all of the sources to the given images. In this example the code is set to run for a maximum of 200 iterations, but will end early if the likelihood and all of the constraints converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starlet_blend = scarlet.Blend(starlet_sources, observation)\n",
    "%time it, logL = starlet_blend.fit(200, e_rel=1e-4)\n",
    "print(f\"scarlet ran for {it} iterations to logL = {logL}\")\n",
    "scarlet.display.show_likelihood(starlet_blend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Full Scene\n",
    "\n",
    "We will use `scarlet.display.show_scene` to render the entire scene. We then show model and data with the same $sinh^{-1}$ stretch and the residuals with a linear stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(starlet_sources, \n",
    "                           norm=norm, \n",
    "                           observation=observation, \n",
    "                           show_rendered=True, \n",
    "                           show_observed=True, \n",
    "                           show_residual=True,\n",
    "                          )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Source Models\n",
    "\n",
    "We will now inspect the model for each source, in its original frame and in its observed frame by leveraging the `show_sources` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(starlet_sources, \n",
    "                             norm=norm, \n",
    "                             observation=observation,\n",
    "                             show_rendered=True, \n",
    "                             show_observed=True,\n",
    "                             add_boxes=True\n",
    "                            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtracting the starlet component\n",
    "\n",
    "We then show the results without the starlet components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsbg = starlet_sources[12].get_model(frame=model_frame)+starlet_sources[16].get_model(frame=model_frame) +starlet_sources[13].get_model(frame=model_frame)\n",
    "model = 0\n",
    "for k in range(len(starlet_sources)):\n",
    "    model += starlet_sources[k].get_model(frame=model_frame)\n",
    "lsbg = observation.render(lsbg)\n",
    "res_rgb = scarlet.display.img_to_rgb(images-lsbg, norm=norm)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "lsbg_rgb = scarlet.display.img_to_rgb(lsbg, norm=norm)\n",
    "model_rgb = scarlet.display.img_to_rgb(images-model, norm=norm)\n",
    "\n",
    "plt.figure(figsize = (30,15))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(lsbg_rgb)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(res_rgb)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
